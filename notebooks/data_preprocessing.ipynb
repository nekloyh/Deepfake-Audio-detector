{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee2055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa # For audio loading and spectrogram\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import jax # Import jax if you want to use jax.random for augmentation\n",
    "import jax.numpy as jnp # Or use numpy for augmentation if you prefer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Cấu hình chung ---\n",
    "DATASET_ROOT = 'dataset'\n",
    "SAMPLE_RATE = 16000 # Phải khớp với SAMPLE_RATE trong prepare_real_audio.py\n",
    "N_MELS = 128        # Số lượng Mel bands\n",
    "N_FFT = 2048        # Kích thước cửa sổ FFT\n",
    "HOP_LENGTH = 512    # Bước nhảy giữa các cửa sổ FFT\n",
    "MAX_AUDIO_DURATION = 10 # Giây (phải khớp với MAX_LEN_SEC trong prepare_real_audio.py)\n",
    "TARGET_SPEC_WIDTH = 256 # Chiều rộng (thời gian) mục tiêu của spectrogram (e.g., 256 frames * HOP_LENGTH/SR ~ 8 giây)\n",
    "                        # Điều chỉnh kích thước này cho phù hợp với model ViT/CNN của bạn.\n",
    "MIN_CLIP_DURATION = 5 # Giây (phải khớp với MIN_LEN_SEC trong prepare_real_audio.py)\n",
    "\n",
    "# Constants for Spectrogram calculation\n",
    "WIN_LENGTH = N_FFT\n",
    "\n",
    "class AudioDeepfakeDatasetJAX:\n",
    "    def __init__(self, metadata_path, dataset_root, sample_rate, n_mels, n_fft, hop_length, \n",
    "                 target_spec_width, augment=None, label_mapping={'real': 0, 'fake': 1}):\n",
    "        self.metadata_df = pd.read_csv(metadata_path)\n",
    "        self.dataset_root = dataset_root\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.target_spec_width = target_spec_width\n",
    "        self.augment = augment # Data augmentation function (e.g., SpecAugment)\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "        # Tính toán số lượng frames tương ứng với MAX_AUDIO_DURATION\n",
    "        # frames = (duration_sec * sample_rate) / hop_length\n",
    "        self.max_frames = int((MAX_AUDIO_DURATION * self.sample_rate) / self.hop_length)\n",
    "\n",
    "        # Lọc bỏ các dòng có đường dẫn audio bị NaN (có thể do lỗi xử lý trước đó)\n",
    "        self.metadata_df = self.metadata_df.dropna(subset=['path'])\n",
    "        \n",
    "        # Tiền xử lý tất cả dữ liệu thành spectrograms và lưu vào bộ nhớ (hoặc disk nếu dataset quá lớn)\n",
    "        # Đối với dataset kích thước vừa phải, lưu vào RAM là nhanh nhất.\n",
    "        self.processed_data = []\n",
    "        logging.info(f\"Bắt đầu tiền xử lý và tải dữ liệu từ '{metadata_path}' vào bộ nhớ...\")\n",
    "        for idx in tqdm(range(len(self.metadata_df)), desc=\"Processing audio files\"):\n",
    "            spec, label, fake_level, path = self._process_single_item(idx)\n",
    "            if spec is not None:\n",
    "                self.processed_data.append((spec, label, fake_level, path))\n",
    "            else:\n",
    "                logging.warning(f\"Bỏ qua mục bị lỗi tại index {idx} trong {metadata_path}\")\n",
    "        logging.info(f\"Đã tải và tiền xử lý {len(self.processed_data)} mẫu.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_data)\n",
    "\n",
    "    def _process_single_item(self, idx):\n",
    "        row = self.metadata_df.iloc[idx]\n",
    "        audio_path_relative = row['path']\n",
    "        label_str = row['label']\n",
    "        fake_level = row.get('fake_level', 0) # Mặc định là 0 cho real\n",
    "\n",
    "        full_audio_path = os.path.join(self.dataset_root, audio_path_relative)\n",
    "\n",
    "        try:\n",
    "            # Tải audio\n",
    "            waveform, sr = librosa.load(full_audio_path, sr=None) # sr=None để giữ sample rate gốc\n",
    "\n",
    "            # Resample nếu cần\n",
    "            if sr != self.sample_rate:\n",
    "                waveform = librosa.resample(y=waveform, orig_sr=sr, target_sr=self.sample_rate)\n",
    "\n",
    "            # Convert waveform to Mel-spectrogram\n",
    "            # librosa.feature.melspectrogram trả về (n_mels, n_frames)\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=waveform,\n",
    "                sr=self.sample_rate,\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.hop_length,\n",
    "                n_mels=self.n_mels,\n",
    "                win_length=WIN_LENGTH\n",
    "            )\n",
    "            \n",
    "            # Chuyển sang log-Mel spectrogram (định dạng log-power)\n",
    "            # Add a small constant to avoid log(0)\n",
    "            mel_spec = librosa.power_to_db(mel_spec, ref=np.max) \n",
    "            \n",
    "            # Chuẩn hóa về [0, 1] hoặc [-1, 1]\n",
    "            # Đây là một bước quan trọng. Có thể chuẩn hóa trên toàn bộ dataset hoặc từng spectrogram.\n",
    "            # Với mô hình CNN/ViT, thường cần input chuẩn hóa.\n",
    "            # Normalizing to [-1, 1] for example:\n",
    "            mel_spec = (mel_spec - mel_spec.min()) / (mel_spec.max() - mel_spec.min()) * 2 - 1\n",
    "\n",
    "\n",
    "            # Pad hoặc cắt spectrogram đến kích thước cố định TARGET_SPEC_WIDTH\n",
    "            current_width = mel_spec.shape[1]\n",
    "            if current_width < self.target_spec_width:\n",
    "                # Pad với 0\n",
    "                pad_amount = self.target_spec_width - current_width\n",
    "                mel_spec = np.pad(mel_spec, ((0, 0), (0, pad_amount)), mode='constant', constant_values=0)\n",
    "            elif current_width > self.target_spec_width:\n",
    "                # Random crop\n",
    "                start_idx = random.randint(0, current_width - self.target_spec_width)\n",
    "                mel_spec = mel_spec[:, start_idx : start_idx + self.target_spec_width]\n",
    "\n",
    "            # Thêm kênh màu (channels-first) cho CNN/ViT, shape: (1, N_MELS, TARGET_SPEC_WIDTH)\n",
    "            mel_spec = np.expand_dims(mel_spec, axis=0)\n",
    "            \n",
    "            label = np.array(self.label_mapping[label_str], dtype=np.int32)\n",
    "            \n",
    "            return mel_spec.astype(np.float32), label, fake_level, row['path']\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Lỗi khi tải hoặc xử lý audio {full_audio_path}: {e}\")\n",
    "            return None, None, None, None\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # Trả về dữ liệu đã tiền xử lý từ bộ nhớ\n",
    "        return self.processed_data[idx]\n",
    "\n",
    "# --- Data Augmentation (JAX-compatible) ---\n",
    "# Chúng ta sẽ viết các hàm augmentation có thể JIT biên dịch\n",
    "def spec_augment(spec, key, freq_mask_param=30, time_mask_param=100, num_freq_masks=1, num_time_masks=1):\n",
    "    \"\"\"\n",
    "    Apply SpecAugment to a spectrogram.\n",
    "    Args:\n",
    "        spec (jnp.ndarray): Spectrogram of shape (channels, N_MELS, TARGET_SPEC_WIDTH).\n",
    "        key (jax.random.PRNGKey): JAX random key for reproducibility.\n",
    "        freq_mask_param (int): Max width of frequency mask.\n",
    "        time_mask_param (int): Max width of time mask.\n",
    "        num_freq_masks (int): Number of frequency masks.\n",
    "        num_time_masks (int): Number of time masks.\n",
    "    Returns:\n",
    "        jnp.ndarray: Augmented spectrogram.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure spec is JAX array\n",
    "    spec = jnp.asarray(spec)\n",
    "\n",
    "    _, n_mels, n_frames = spec.shape\n",
    "    \n",
    "    for _ in range(num_freq_masks):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        f = jax.random.randint(subkey, (), 0, freq_mask_param)\n",
    "        key, subkey = jax.random.split(key)\n",
    "        f0 = jax.random.randint(subkey, (), 0, n_mels - f)\n",
    "        spec = spec.at[:, f0:f0+f, :].set(0.0) # Set to 0 (or mean)\n",
    "        \n",
    "    for _ in range(num_time_masks):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        t = jax.random.randint(subkey, (), 0, time_mask_param)\n",
    "        key, subkey = jax.random.split(key)\n",
    "        t0 = jax.random.randint(subkey, (), 0, n_frames - t)\n",
    "        spec = spec.at[:, :, t0:t0+t].set(0.0) # Set to 0 (or mean)\n",
    "        \n",
    "    return spec\n",
    "\n",
    "# --- Batch Generator ---\n",
    "def data_generator(dataset, batch_size, rng_key=None, shuffle=True, repeat=False):\n",
    "    \"\"\"\n",
    "    A generator that yields batches of data (NumPy arrays).\n",
    "    \"\"\"\n",
    "    data_indices = list(range(len(dataset)))\n",
    "    \n",
    "    while True:\n",
    "        if shuffle:\n",
    "            random.shuffle(data_indices)\n",
    "        \n",
    "        for i in range(0, len(data_indices), batch_size):\n",
    "            batch_indices = data_indices[i:i + batch_size]\n",
    "            \n",
    "            batch_specs = []\n",
    "            batch_labels = []\n",
    "            batch_fake_levels = []\n",
    "            batch_paths = []\n",
    "\n",
    "            for idx in batch_indices:\n",
    "                spec, label, fake_level, path = dataset[idx]\n",
    "                batch_specs.append(spec)\n",
    "                batch_labels.append(label)\n",
    "                batch_fake_levels.append(fake_level)\n",
    "                batch_paths.append(path)\n",
    "            \n",
    "            # Stack into NumPy arrays\n",
    "            yield np.stack(batch_specs), np.stack(batch_labels), np.array(batch_fake_levels), batch_paths\n",
    "        \n",
    "        if not repeat:\n",
    "            break\n",
    "\n",
    "# --- Hàm để khởi tạo Dataset và Generator ---\n",
    "def get_data_generator(set_type, batch_size, rng_key, shuffle=True, repeat=False, num_workers=0, include_fake_levels=None):\n",
    "    \"\"\"\n",
    "    Initializes the dataset and returns a batch generator.\n",
    "    num_workers is a placeholder for potential future multiprocessing.\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(DATASET_ROOT, set_type, f'combined_metadata_{set_type}.csv')\n",
    "    \n",
    "    df_raw = pd.read_csv(metadata_path)\n",
    "    \n",
    "    # Lọc dữ liệu theo fake_level nếu yêu cầu\n",
    "    if include_fake_levels is not None:\n",
    "        if not isinstance(include_fake_levels, list):\n",
    "            include_fake_levels = [include_fake_levels]\n",
    "        # Tạo mask để lọc\n",
    "        mask = df_raw['fake_level'].isin(include_fake_levels)\n",
    "        # Đặc biệt xử lý trường hợp fake_level 0 (real)\n",
    "        if 0 in include_fake_levels:\n",
    "            mask = mask | (df_raw['fake_level'] == 0)\n",
    "        df_filtered = df_raw[mask].copy()\n",
    "        logging.info(f\"Đã lọc dataset '{set_type}' để chỉ bao gồm fake_level: {include_fake_levels}. Số lượng mẫu: {len(df_filtered)}\")\n",
    "    else:\n",
    "        df_filtered = df_raw.copy()\n",
    "\n",
    "    # Tạo một bản sao của DataFrame đã lọc cho dataset\n",
    "    # Cần một dataset riêng cho mỗi lần gọi get_data_generator nếu muốn lọc khác nhau\n",
    "    dataset = AudioDeepfakeDatasetJAX(\n",
    "        metadata_path=metadata_path, # Vẫn truyền metadata path gốc để tải tất cả\n",
    "        dataset_root=DATASET_ROOT,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_mels=N_MELS,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        target_spec_width=TARGET_SPEC_WIDTH,\n",
    "        augment=spec_augment if set_type == 'train' else None # Chỉ áp dụng augmentation cho tập train\n",
    "    )\n",
    "    # Cập nhật metadata_df của dataset để nó chỉ chứa dữ liệu đã lọc\n",
    "    # Note: processed_data đã được tạo từ metadata_df ban đầu, nên cần lọc lại processed_data\n",
    "    original_processed_data = dataset.processed_data\n",
    "    dataset.processed_data = []\n",
    "    \n",
    "    # Lọc processed_data dựa trên df_filtered\n",
    "    filtered_paths = set(df_filtered['path'].tolist())\n",
    "    for spec, label, fake_level, path in original_processed_data:\n",
    "        if path in filtered_paths:\n",
    "            dataset.processed_data.append((spec, label, fake_level, path))\n",
    "\n",
    "    logging.info(f\"Số lượng mẫu sau khi lọc cho '{set_type}': {len(dataset.processed_data)}\")\n",
    "\n",
    "    return data_generator(dataset, batch_size, rng_key=rng_key, shuffle=shuffle, repeat=repeat)\n",
    "\n",
    "\n",
    "# --- Ví dụ sử dụng ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Khởi tạo JAX RNG key\n",
    "    key = jax.random.PRNGKey(0)\n",
    "\n",
    "    # Test Data Generator\n",
    "    logging.info(\"Kiểm tra Data Generator cho tập train...\")\n",
    "    train_gen = get_data_generator('train', batch_size=4, rng_key=key, shuffle=True, \n",
    "                                   include_fake_levels=[0, 1, 3, 4]) # Bao gồm real và các mức fake\n",
    "    \n",
    "    # Lấy một vài batch\n",
    "    for i, (specs, labels, fake_levels, paths) in enumerate(train_gen):\n",
    "        print(f\"\\nBatch {i+1}:\")\n",
    "        print(f\"  Spectrograms shape: {specs.shape}\") # Expected: (batch_size, 1, N_MELS, TARGET_SPEC_WIDTH)\n",
    "        print(f\"  Labels: {labels}\")\n",
    "        print(f\"  Fake Levels: {fake_levels}\")\n",
    "        print(f\"  Paths (first 2): {paths[:2]}\")\n",
    "        \n",
    "        # Test augmentation if it's applied\n",
    "        if i == 0 and 'train' in train_gen.__self__.dataset.metadata_df['path'].iloc[0] and train_gen.__self__.dataset.augment:\n",
    "             # Apply augmentation to a sample spec (need a JAX key for this)\n",
    "            sub_key = jax.random.split(key)[0] # Just take one subkey for demonstration\n",
    "            augmented_spec = spec_augment(specs[0], sub_key)\n",
    "            print(f\"  Augmented spec shape: {augmented_spec.shape}\")\n",
    "            # You can add visualization here if needed (e.g., matplotlib)\n",
    "            \n",
    "        if i >= 1: # Chỉ lấy 2 batch để kiểm tra\n",
    "            break\n",
    "\n",
    "    logging.info(\"\\nKiểm tra Data Generator cho tập val (không shuffle, không augment)...\")\n",
    "    val_gen = get_data_generator('val', batch_size=4, rng_key=key, shuffle=False)\n",
    "    for i, (specs, labels, fake_levels, paths) in enumerate(val_gen):\n",
    "        print(f\"\\nBatch {i+1}:\")\n",
    "        print(f\"  Spectrograms shape: {specs.shape}\")\n",
    "        print(f\"  Labels: {labels}\")\n",
    "        print(f\"  Fake Levels: {fake_levels}\")\n",
    "        if i >= 0:\n",
    "            break\n",
    "\n",
    "    logging.info(\"\\nKiểm tra Data Generator cho tập test (không shuffle, không augment)...\")\n",
    "    test_gen = get_data_generator('test', batch_size=4, rng_key=key, shuffle=False)\n",
    "    for i, (specs, labels, fake_levels, paths) in enumerate(test_gen):\n",
    "        print(f\"\\nBatch {i+1}:\")\n",
    "        print(f\"  Spectrograms shape: {specs.shape}\")\n",
    "        print(f\"  Labels: {labels}\")\n",
    "        print(f\"  Fake Levels: {fake_levels}\")\n",
    "        if i >= 0:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
