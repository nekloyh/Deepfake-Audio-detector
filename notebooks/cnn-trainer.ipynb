{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b29f5e",
   "metadata": {
    "papermill": {
     "duration": 0.003257,
     "end_time": "2025-06-09T10:05:22.857926",
     "exception": false,
     "start_time": "2025-06-09T10:05:22.854669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b390f6a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T10:05:22.863994Z",
     "iopub.status.busy": "2025-06-09T10:05:22.863794Z",
     "iopub.status.idle": "2025-06-09T10:05:33.834888Z",
     "shell.execute_reply": "2025-06-09T10:05:33.833886Z"
    },
    "papermill": {
     "duration": 10.975604,
     "end_time": "2025-06-09T10:05:33.836403",
     "exception": false,
     "start_time": "2025-06-09T10:05:22.860799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnekloyh\u001b[0m (\u001b[33mnekloyh-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB login successful using wandb_api_key.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "# from einops import rearrange # Not needed for CNNs\n",
    "# from einops.layers.torch import Rearrange # Not needed for CNNs\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import wandb \n",
    "from dataclasses import dataclass, field  # Import field for default_factory\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# WandB login (assuming you have your API key set up)\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "try:\n",
    "    secret_value_0 = user_secrets.get_secret(\"wandb_api_key\")\n",
    "    wandb.login(key=secret_value_0)\n",
    "    print(\"WandB login successful using wandb_api_key.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to login to WandB: {e}. Please ensure WANDB_API_KEY is set.\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d72c61",
   "metadata": {
    "papermill": {
     "duration": 0.003847,
     "end_time": "2025-06-09T10:05:33.845341",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.841494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9dbab34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T10:05:33.854977Z",
     "iopub.status.busy": "2025-06-09T10:05:33.854599Z",
     "iopub.status.idle": "2025-06-09T10:05:33.864246Z",
     "shell.execute_reply": "2025-06-09T10:05:33.863657Z"
    },
    "papermill": {
     "duration": 0.015271,
     "end_time": "2025-06-09T10:05:33.865249",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.849978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # Data processing parameters\n",
    "    SEED: int = 42\n",
    "    SR: int = 16000\n",
    "    N_FFT: int = 2048\n",
    "    HOP_LENGTH: int = 512\n",
    "    N_MELS: int = 128\n",
    "    FMIN: float = 0.0\n",
    "    FMAX: float = 8000.0\n",
    "    NUM_TIME_MASKS: int = 2\n",
    "    NUM_FREQ_MASKS: int = 2\n",
    "    TIME_MASK_MAX_WIDTH: int = 30\n",
    "    FREQ_MASK_MAX_WIDTH: int = 15\n",
    "    MASK_REPLACEMENT_VALUE: float = -80.0\n",
    "    NORM_EPSILON: float = 1e-6\n",
    "    LOUDNESS_LUFS: float = -23.0\n",
    "    USE_GLOBAL_NORMALIZATION: bool = True\n",
    "    USE_RANDOM_CROPPING: bool = True\n",
    "    CACHE_DIR_BASE: str = \"/kaggle/input/cnn-3s-dataset\"\n",
    "    DATASET_SUBDIR: str = \"cnn_3s_dataset\"\n",
    "    train_dir: str = \"train\"\n",
    "    val_dir: str = \"val\"\n",
    "    test_dir: str = \"test\"\n",
    "    metadata_file: str = \"kaggle_metadata.csv\"\n",
    "\n",
    "    # Model architecture\n",
    "    img_size: int = 224\n",
    "    num_classes: int = 2\n",
    "    in_channels: int = 1\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    # CNN specific architecture parameters\n",
    "    cnn_conv_channels: list[int] = field(default_factory=list)\n",
    "    cnn_pool_after_conv: list[bool] = field(default_factory=list)\n",
    "    linear_output_units_1st_fc: int = 512  # Fixed: Added missing attribute\n",
    "\n",
    "    # Training parameters\n",
    "    learning_rate: float = 1e-4\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 20\n",
    "    weight_decay: float = 1e-4\n",
    "    num_workers: int = 4\n",
    "\n",
    "    # Data augmentation\n",
    "    apply_augmentation: bool = True\n",
    "    augmentation_prob: float = 0.5\n",
    "    audio_length_seconds: float = 3.0\n",
    "    overlap_ratio: float = 0.5\n",
    "\n",
    "    model_size: str = \"\"\n",
    "    dataset_name: str = \"\"\n",
    "\n",
    "    def validate(self):\n",
    "        assert self.learning_rate > 0, \"learning_rate must be positive\"\n",
    "        assert self.batch_size > 0, \"batch_size must be positive\"\n",
    "        assert self.epochs > 0, \"epochs must be positive\"\n",
    "        assert self.num_workers >= 0, \"num_workers must be non-negative\"\n",
    "        assert len(self.cnn_conv_channels) == len(self.cnn_pool_after_conv), (\n",
    "            \"cnn_conv_channels and cnn_pool_after_conv must have the same length\"\n",
    "        )\n",
    "\n",
    "    def get_full_cache_dir(self):\n",
    "        return os.path.join(self.CACHE_DIR_BASE, self.DATASET_SUBDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc52af06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T10:05:33.878242Z",
     "iopub.status.busy": "2025-06-09T10:05:33.877508Z",
     "iopub.status.idle": "2025-06-09T10:05:33.884822Z",
     "shell.execute_reply": "2025-06-09T10:05:33.884038Z"
    },
    "papermill": {
     "duration": 0.01601,
     "end_time": "2025-06-09T10:05:33.886405",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.870395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_CONFIG = Config()\n",
    "\n",
    "# Lấy tất cả các tham số từ BASE_CONFIG ngoại trừ các tham số mà chúng ta muốn ghi đè riêng cho từng loại model\n",
    "base_params = {\n",
    "    f.name: getattr(BASE_CONFIG, f.name)\n",
    "    for f in BASE_CONFIG.__dataclass_fields__.values()\n",
    "    if f.init and f.name not in [\"model_size\", \"dataset_name\", \"cnn_conv_channels\", \n",
    "                                 \"cnn_pool_after_conv\", \"linear_output_units_1st_fc\"]\n",
    "}\n",
    "\n",
    "ALL_MODEL_CONFIGS = {\n",
    "    \"CNN_Small\": Config(\n",
    "        **base_params,\n",
    "        model_size=\"CNN_Small\",\n",
    "        dataset_name=\"cnn_3s_dataset\",\n",
    "        cnn_conv_channels=[32, 64, 128],  # Reduced channels\n",
    "        cnn_pool_after_conv=[True, True, True],\n",
    "        linear_output_units_1st_fc=192,  # Reduced FC units\n",
    "    ),\n",
    "    # CNN Large: Target 5-7M parameters\n",
    "    \"CNN_Large\": Config(\n",
    "        **base_params,\n",
    "        model_size=\"CNN_Large\",\n",
    "        dataset_name=\"cnn_3s_dataset\",\n",
    "        cnn_conv_channels=[64, 128, 256, 512, 512],  # More layers and channels\n",
    "        cnn_pool_after_conv=[True, True, True, True, False],\n",
    "        linear_output_units_1st_fc=192,  # Larger FC units\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19832329",
   "metadata": {
    "papermill": {
     "duration": 0.00302,
     "end_time": "2025-06-09T10:05:33.894659",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.891639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2226d2d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T10:05:33.901220Z",
     "iopub.status.busy": "2025-06-09T10:05:33.900942Z",
     "iopub.status.idle": "2025-06-09T10:05:33.914793Z",
     "shell.execute_reply": "2025-06-09T10:05:33.913972Z"
    },
    "papermill": {
     "duration": 0.018892,
     "end_time": "2025-06-09T10:05:33.916415",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.897523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_Audio(nn.Module):\n",
    "    def __init__(self, img_size: int, in_channels: int, num_classes: int,\n",
    "                 linear_output_units_1st_fc: int,\n",
    "                 cnn_conv_channels: list[int], cnn_pool_after_conv: list[bool], \n",
    "                 dropout: float = 0.3):\n",
    "        super(CNN_Audio, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.cnn_conv_channels = cnn_conv_channels\n",
    "        self.cnn_pool_after_conv = cnn_pool_after_conv\n",
    "        self.img_size = img_size\n",
    "        self.dropout = dropout\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Build convolutional layers with proper architecture\n",
    "        layers = []\n",
    "        in_dim = self.in_channels\n",
    "        \n",
    "        for i, out_dim in enumerate(self.cnn_conv_channels):\n",
    "            # Convolutional block\n",
    "            layers.append(nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(out_dim))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            \n",
    "            # Optional pooling\n",
    "            if self.cnn_pool_after_conv[i]:\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            \n",
    "            # Dropout for regularization\n",
    "            layers.append(nn.Dropout2d(self.dropout))\n",
    "            in_dim = out_dim\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "        # Calculate flattened size dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, self.in_channels, self.img_size, self.img_size)\n",
    "            dummy_output = self.conv_layers(dummy_input)\n",
    "            self.flattened_size = dummy_output.view(1, -1).size(1)\n",
    "\n",
    "        # Adaptive average pooling to reduce feature map size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        \n",
    "        # Calculate size after adaptive pooling\n",
    "        with torch.no_grad():\n",
    "            dummy_pooled = self.adaptive_pool(dummy_output)\n",
    "            self.pooled_size = dummy_pooled.view(1, -1).size(1)\n",
    "\n",
    "        # Classifier with proper architecture\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.pooled_size, linear_output_units_1st_fc),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(linear_output_units_1st_fc, linear_output_units_1st_fc // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(linear_output_units_1st_fc // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aad2ccb",
   "metadata": {
    "papermill": {
     "duration": 0.002586,
     "end_time": "2025-06-09T10:05:33.922330",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.919744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6eeb9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T10:05:33.928751Z",
     "iopub.status.busy": "2025-06-09T10:05:33.928556Z",
     "iopub.status.idle": "2025-06-09T10:05:33.940271Z",
     "shell.execute_reply": "2025-06-09T10:05:33.939752Z"
    },
    "papermill": {
     "duration": 0.016177,
     "end_time": "2025-06-09T10:05:33.941272",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.925095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, cache_dir: str, set_type: str, n_mels: int, config: Config):\n",
    "        self.cache_path = os.path.join(cache_dir, getattr(config, f\"{set_type}_dir\"))\n",
    "        self.metadata_path = os.path.join(self.cache_path, config.metadata_file)\n",
    "        self.n_mels = n_mels\n",
    "        self.training = set_type == \"train\"\n",
    "        self.config = config\n",
    "\n",
    "        if not os.path.exists(self.metadata_path):\n",
    "            raise FileNotFoundError(f\"Metadata file not found: {self.metadata_path}\")\n",
    "        self.metadata = pd.read_csv(self.metadata_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        npy_path = os.path.join(self.cache_path, row[\"npy_path\"])\n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(npy_path):\n",
    "                raise FileNotFoundError(f\"Spectrogram file not found: {npy_path}\")\n",
    "            spectrogram = np.load(npy_path)\n",
    "            spectrogram = self._preprocess_spectrogram(spectrogram)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {npy_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "        return spectrogram, torch.tensor(label).long()\n",
    "\n",
    "    def _preprocess_spectrogram(self, spec):\n",
    "        if isinstance(spec, np.ndarray):\n",
    "            spec = torch.from_numpy(spec).float()\n",
    "\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "        elif spec.ndim == 4:\n",
    "            spec = spec.squeeze(0)\n",
    "\n",
    "        if spec.shape[-2:] != (self.config.img_size, self.config.img_size):\n",
    "            spec = F.interpolate(\n",
    "                spec.unsqueeze(0),\n",
    "                size=(self.config.img_size, self.config.img_size),\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False,\n",
    "            ).squeeze(0)\n",
    "\n",
    "        if self.config.USE_GLOBAL_NORMALIZATION:\n",
    "            mean = spec.mean()\n",
    "            std = spec.std() + self.config.NORM_EPSILON\n",
    "            spec = (spec - mean) / std\n",
    "\n",
    "        # Apply augmentation during training\n",
    "        if self.training and self.config.apply_augmentation:\n",
    "            # Frequency masking\n",
    "            for _ in range(self.config.NUM_FREQ_MASKS):\n",
    "                freq_mask_width = torch.randint(\n",
    "                    0, self.config.FREQ_MASK_MAX_WIDTH, (1,)\n",
    "                ).item()\n",
    "                freq_start = torch.randint(\n",
    "                    0, max(1, spec.shape[-2] - freq_mask_width), (1,)\n",
    "                ).item()\n",
    "                spec[:, freq_start : freq_start + freq_mask_width, :] = (\n",
    "                    self.config.MASK_REPLACEMENT_VALUE\n",
    "                )\n",
    "            \n",
    "            # Time masking\n",
    "            for _ in range(self.config.NUM_TIME_MASKS):\n",
    "                time_mask_width = torch.randint(\n",
    "                    0, self.config.TIME_MASK_MAX_WIDTH, (1,)\n",
    "                ).item()\n",
    "                time_start = torch.randint(\n",
    "                    0, max(1, spec.shape[-1] - time_mask_width), (1,)\n",
    "                ).item()\n",
    "                spec[:, :, time_start : time_start + time_mask_width] = (\n",
    "                    self.config.MASK_REPLACEMENT_VALUE\n",
    "                )\n",
    "\n",
    "        return spec\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"Custom collate function to handle None values and invalid shapes\"\"\"\n",
    "    valid_batch = [item for item in batch if item is not None]\n",
    "\n",
    "    if not valid_batch:\n",
    "        print(\"Warning: Empty batch after filtering\")\n",
    "        return torch.empty(0, 1, 224, 224), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    data_list, label_list = zip(*valid_batch)\n",
    "    expected_shape = (1, 224, 224)\n",
    "    valid_data = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for data, label in zip(data_list, label_list):\n",
    "        if isinstance(data, torch.Tensor) and data.shape == expected_shape:\n",
    "            valid_data.append(data)\n",
    "            valid_labels.append(label)\n",
    "        else:\n",
    "            print(\n",
    "                f\"Warning: Skipping invalid shape {data.shape if hasattr(data, 'shape') else type(data)} for data with label {label}\"\n",
    "            )\n",
    "\n",
    "    if not valid_data:\n",
    "        print(\"Warning: No valid data in batch\")\n",
    "        return torch.empty(0, 1, 224, 224), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    return torch.stack(valid_data, dim=0), torch.stack(valid_labels, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79903035",
   "metadata": {
    "papermill": {
     "duration": 0.00269,
     "end_time": "2025-06-09T10:05:33.946691",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.944001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfd94ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T10:05:33.953702Z",
     "iopub.status.busy": "2025-06-09T10:05:33.953514Z",
     "iopub.status.idle": "2025-06-09T10:05:33.978672Z",
     "shell.execute_reply": "2025-06-09T10:05:33.978174Z"
    },
    "papermill": {
     "duration": 0.030189,
     "end_time": "2025-06-09T10:05:33.979671",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.949482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_dataset(dataset, name):\n",
    "    invalid_count = 0\n",
    "    invalid_files = []\n",
    "    for idx in range(len(dataset)):\n",
    "        row = dataset.metadata.iloc[idx]\n",
    "        npy_path = os.path.join(dataset.cache_path, row[\"npy_path\"])\n",
    "        if not os.path.exists(npy_path):\n",
    "            invalid_count += 1\n",
    "            invalid_files.append(npy_path)\n",
    "    if invalid_count > 0:\n",
    "        print(f\"Warning: {invalid_count} invalid samples found in {name} dataset\")\n",
    "        for f in invalid_files[:5]:\n",
    "            print(f\" - Missing file: {f}\")\n",
    "        if len(invalid_files) > 5:\n",
    "            print(f\" ... and {len(invalid_files) - 5} more\")\n",
    "    return invalid_count\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, val_loader, optimizer, criterion, device, num_epochs, run_name\n",
    "):\n",
    "    model.to(device)\n",
    "    best_val_f1 = -1\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    warmup_epochs = 3\n",
    "\n",
    "    # Đã cập nhật: Đảm bảo T_max được tính toán chính xác\n",
    "    # Lịch trình Cosine Annealing cho phần sau của quá trình đào tạo\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_epochs - warmup_epochs, eta_min=1e-6\n",
    "    )\n",
    "    # Lịch trình Warmup cho các epoch đầu tiên\n",
    "    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer,\n",
    "        lr_lambda=lambda epoch: (epoch + 1) / warmup_epochs\n",
    "        if epoch < warmup_epochs\n",
    "        else 1.0,\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            if batch is None or len(batch[0]) == 0:\n",
    "                print(f\"Warning: Skipping empty batch at index {batch_idx}\")\n",
    "                continue\n",
    "\n",
    "            data, labels = batch\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        if batch_count == 0:\n",
    "            print(f\"Error: No valid batches in epoch {epoch + 1}\")\n",
    "            continue\n",
    "\n",
    "        if epoch < warmup_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        val_loss, val_preds, val_labels, val_probs = evaluate_model(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average=\"binary\")\n",
    "        val_roc_auc = roc_auc_score(val_labels, val_probs[:, 1])\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}: Train Loss: {total_loss / batch_count:.4f}, \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": total_loss / batch_count,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_f1\": val_f1,\n",
    "                \"val_accuracy\": val_acc,\n",
    "                \"val_roc_auc\": val_roc_auc,\n",
    "                \"learning_rate\": optimizer.param_groups[0][\"lr\"],\n",
    "                \"warmup_phase\": epoch < warmup_epochs,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "            model_save_path = f\"best_model_{run_name}.pth\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"best_val_f1\": best_val_f1,\n",
    "                },\n",
    "                model_save_path,\n",
    "            )\n",
    "            print(f\"Saved best model with F1: {best_val_f1:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device, return_cm=False):\n",
    "    \"\"\"Enhanced evaluation function\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "        for batch in pbar:\n",
    "            if batch is None or len(batch[0]) == 0:\n",
    "                continue\n",
    "            \n",
    "            data, labels = batch\n",
    "            if -1 in labels.cpu().numpy():\n",
    "                continue\n",
    "\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    if len(all_labels) < 2:\n",
    "        print(\"Warning: Too few samples for reliable evaluation\")\n",
    "        return (\n",
    "            float(\"inf\"),\n",
    "            [],\n",
    "            [],\n",
    "            np.array([]),\n",
    "            np.zeros((2, 2)) if return_cm else None,\n",
    "        )\n",
    "\n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else 0.0\n",
    "    \n",
    "    if return_cm:\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        return avg_loss, all_preds, all_labels, np.array(all_probs), cm\n",
    "    \n",
    "    return avg_loss, all_preds, all_labels, np.array(all_probs)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, run_name, save_dir=\"results\"):\n",
    "    \"\"\"Plot and save confusion matrix\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Real\", \"Fake\"],\n",
    "        yticklabels=[\"Real\", \"Fake\"],\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"Confusion Matrix - {run_name}\")\n",
    "    cm_plot_path = os.path.join(save_dir, f\"cm_{run_name}.png\")\n",
    "    fig.savefig(cm_plot_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return cm_plot_path\n",
    "\n",
    "\n",
    "def run_training(training_params):\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    torch.manual_seed(Config.SEED)\n",
    "    np.random.seed(Config.SEED)\n",
    "\n",
    "    model_size = training_params[\"model_size\"]\n",
    "    epochs = training_params[\"epochs\"]\n",
    "    learning_rate = training_params[\"learning_rate\"]\n",
    "    batch_size = training_params[\"batch_size\"]\n",
    "    num_workers = training_params[\"num_workers\"]\n",
    "\n",
    "    if model_size not in ALL_MODEL_CONFIGS:\n",
    "        print(f\"Error: Model size '{model_size}' not found in ALL_MODEL_CONFIGS.\")\n",
    "        return\n",
    "\n",
    "    config = ALL_MODEL_CONFIGS[model_size]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize improved model\n",
    "    model = CNN_Audio(\n",
    "        img_size=config.img_size,\n",
    "        in_channels=config.in_channels,\n",
    "        num_classes=config.num_classes,\n",
    "        linear_output_units_1st_fc=config.linear_output_units_1st_fc,\n",
    "        cnn_conv_channels=config.cnn_conv_channels,\n",
    "        cnn_pool_after_conv=config.cnn_pool_after_conv,\n",
    "        dropout=config.dropout,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Configuring {model_size} model with {param_count:,} parameters...\")\n",
    "\n",
    "    # Sử dụng hàm get_full_cache_dir để tạo đường dẫn dataset\n",
    "    model_cache_dir = config.get_full_cache_dir()\n",
    "    print(f\"Loading data from: {model_cache_dir}\")\n",
    "\n",
    "    # Khởi tạo dataset với 'config' hoàn chỉnh\n",
    "    train_dataset = AudioDataset(model_cache_dir, \"train\", config.N_MELS, config)\n",
    "    val_dataset = AudioDataset(model_cache_dir, \"val\", config.N_MELS, config)\n",
    "    test_dataset = AudioDataset(model_cache_dir, \"test\", config.N_MELS, config)\n",
    "\n",
    "    for dataset, name in [\n",
    "        (train_dataset, \"train\"),\n",
    "        (val_dataset, \"val\"),\n",
    "        (test_dataset, \"test\"),\n",
    "    ]:\n",
    "        invalid_count = validate_dataset(dataset, name)\n",
    "        if invalid_count == len(dataset):\n",
    "            print(f\"Error: All samples in {name} dataset are invalid\")\n",
    "            return\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=custom_collate_fn,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    print(f\"Using Batch size: {batch_size}\")\n",
    "\n",
    "    class_counts = np.bincount(\n",
    "        [\n",
    "            train_dataset[i][1].item()\n",
    "            for i in range(len(train_dataset))\n",
    "            if train_dataset[i] is not None\n",
    "        ]\n",
    "    )\n",
    "    if 0 in class_counts:\n",
    "        print(\n",
    "            f\"Error: Class {np.argwhere(class_counts == 0).flatten()} has no samples in training dataset\"\n",
    "        )\n",
    "        return\n",
    "    class_weights = torch.tensor(\n",
    "        [1.0 / max(count, 1e-6) for count in class_counts], dtype=torch.float\n",
    "    ).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=config.weight_decay\n",
    "    )\n",
    "\n",
    "    run_name = f\"{model_size}_{config.dataset_name}_{datetime.now().strftime('%H%M%S')}\"\n",
    "    wandb.init(project=\"audio-deepfake-detection\", name=run_name, config=training_params) # Logging training_params\n",
    "\n",
    "    trained_model = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        epochs,\n",
    "        run_name\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Evaluating {model_size} on Test Set ({config.dataset_name}) ---\")\n",
    "    test_loss, test_preds, test_labels, test_probs, test_cm = evaluate_model(\n",
    "        trained_model, test_loader, criterion, device, return_cm=True\n",
    "    )\n",
    "\n",
    "    test_acc = accuracy_score(test_labels, test_preds)\n",
    "    test_f1 = f1_score(test_labels, test_preds, average=\"binary\")\n",
    "    test_roc_auc = roc_auc_score(test_labels, test_probs[:, 1])\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test F1-score: {test_f1:.4f}\")\n",
    "    print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "    cm_plot_path = plot_confusion_matrix(test_cm, run_name=run_name, save_dir=\"results\")\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"test_f1_score\": test_f1,\n",
    "            \"test_roc_auc\": test_roc_auc,\n",
    "            \"confusion_matrix\": wandb.Image(cm_plot_path),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381f37a",
   "metadata": {
    "papermill": {
     "duration": 0.002493,
     "end_time": "2025-06-09T10:05:33.984907",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.982414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define training parameters for CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59d5cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T10:05:33.990978Z",
     "iopub.status.busy": "2025-06-09T10:05:33.990779Z",
     "iopub.status.idle": "2025-06-09T14:49:57.268020Z",
     "shell.execute_reply": "2025-06-09T14:49:57.267265Z"
    },
    "papermill": {
     "duration": 17063.281627,
     "end_time": "2025-06-09T14:49:57.269216",
     "exception": false,
     "start_time": "2025-06-09T10:05:33.987589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training CNN_Small ===\n",
      "Using device: cuda\n",
      "Configuring CNN_Small model with 505,026 parameters...\n",
      "Loading data from: /kaggle/input/cnn-3s-dataset/cnn_3s_dataset\n",
      "Train samples: 102896\n",
      "Validation samples: 6996\n",
      "Test samples: 14066\n",
      "Using Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250609_102208-7lprh2ra\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCNN_Small_cnn_3s_dataset_102208\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nekloyh-none/audio-deepfake-detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nekloyh-none/audio-deepfake-detection/runs/7lprh2ra\u001b[0m\n",
      "Epoch 1/20: 100%|██████████| 3216/3216 [03:25<00:00, 15.62it/s, loss=0.4595]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6231, Val Loss: 0.6531, Val F1: 0.7382\n",
      "Saved best model with F1: 0.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 3216/3216 [03:24<00:00, 15.72it/s, loss=0.6416]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.4416, Val Loss: 0.4796, Val F1: 0.8204\n",
      "Saved best model with F1: 0.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 3216/3216 [03:26<00:00, 15.54it/s, loss=0.3731]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.3627, Val Loss: 0.2643, Val F1: 0.8773\n",
      "Saved best model with F1: 0.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 3216/3216 [03:24<00:00, 15.70it/s, loss=0.6315]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.3278, Val Loss: 0.2423, Val F1: 0.8835\n",
      "Saved best model with F1: 0.8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.83it/s, loss=0.2182]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.3095, Val Loss: 0.2426, Val F1: 0.8873\n",
      "Saved best model with F1: 0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 3216/3216 [03:22<00:00, 15.89it/s, loss=0.0841]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.2973, Val Loss: 0.2358, Val F1: 0.8870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.78it/s, loss=0.2155]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.2881, Val Loss: 0.1974, Val F1: 0.9079\n",
      "Saved best model with F1: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.80it/s, loss=0.3576]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.2801, Val Loss: 0.2108, Val F1: 0.9183\n",
      "Saved best model with F1: 0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 3216/3216 [03:24<00:00, 15.71it/s, loss=0.2135]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.2750, Val Loss: 0.1869, Val F1: 0.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.77it/s, loss=0.3305]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.2683, Val Loss: 0.1867, Val F1: 0.9148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.81it/s, loss=0.1450]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.2633, Val Loss: 0.1681, Val F1: 0.9324\n",
      "Saved best model with F1: 0.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.82it/s, loss=0.1498]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.2580, Val Loss: 0.1668, Val F1: 0.9346\n",
      "Saved best model with F1: 0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 3216/3216 [03:22<00:00, 15.85it/s, loss=0.1038]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.2559, Val Loss: 0.1667, Val F1: 0.9319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.84it/s, loss=0.1342]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.2507, Val Loss: 0.1921, Val F1: 0.9093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 3216/3216 [03:24<00:00, 15.72it/s, loss=0.1116]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.2482, Val Loss: 0.1529, Val F1: 0.9425\n",
      "Saved best model with F1: 0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 3216/3216 [03:24<00:00, 15.71it/s, loss=0.1580]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss: 0.2445, Val Loss: 0.1591, Val F1: 0.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.83it/s, loss=0.1096]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 0.2416, Val Loss: 0.1495, Val F1: 0.9370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.83it/s, loss=0.3040]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 0.2397, Val Loss: 0.1545, Val F1: 0.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 3216/3216 [03:25<00:00, 15.67it/s, loss=0.1141]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 0.2392, Val Loss: 0.1524, Val F1: 0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 3216/3216 [03:23<00:00, 15.79it/s, loss=0.2878]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 0.2383, Val Loss: 0.1524, Val F1: 0.9350\n",
      "Early stopping at epoch 20\n",
      "\n",
      "--- Evaluating CNN_Small on Test Set (cnn_3s_dataset) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1573\n",
      "Test Accuracy: 0.9291\n",
      "Test F1-score: 0.9317\n",
      "Test ROC AUC: 0.9876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: learning_rate ▆████▇▇▇▆▅▅▄▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_f1_score ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     test_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_loss █▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▄▆▆▆▆▇▇▇▇███▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_f1 ▁▄▆▆▆▆▇▇▇▇███▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▆▃▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_roc_auc ▁▅▆▇▇▇▇▇████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_accuracy 0.92912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_f1_score 0.93167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     test_loss 0.1573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_roc_auc 0.98755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_loss 0.23831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.93239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_f1 0.935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.1524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_roc_auc 0.98939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  warmup_phase False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mCNN_Small_cnn_3s_dataset_102208\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/nekloyh-none/audio-deepfake-detection/runs/7lprh2ra\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/nekloyh-none/audio-deepfake-detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250609_102208-7lprh2ra/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training CNN_Large ===\n",
      "Using device: cuda\n",
      "Configuring CNN_Large model with 5,502,882 parameters...\n",
      "Loading data from: /kaggle/input/cnn-3s-dataset/cnn_3s_dataset\n",
      "Train samples: 102896\n",
      "Validation samples: 6996\n",
      "Test samples: 14066\n",
      "Using Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250609_114040-ccw9piht\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCNN_Large_cnn_3s_dataset_114040\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nekloyh-none/audio-deepfake-detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nekloyh-none/audio-deepfake-detection/runs/ccw9piht\u001b[0m\n",
      "Epoch 1/20: 100%|██████████| 3216/3216 [09:13<00:00,  5.81it/s, loss=0.3611]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.5333, Val Loss: 0.2403, Val F1: 0.8871\n",
      "Saved best model with F1: 0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 3216/3216 [09:12<00:00,  5.82it/s, loss=0.1481]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.3268, Val Loss: 0.2099, Val F1: 0.9034\n",
      "Saved best model with F1: 0.9034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 3216/3216 [09:11<00:00,  5.83it/s, loss=0.3027]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.2978, Val Loss: 0.1809, Val F1: 0.9280\n",
      "Saved best model with F1: 0.9280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 3216/3216 [09:13<00:00,  5.81it/s, loss=0.2794]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.2700, Val Loss: 0.1526, Val F1: 0.9361\n",
      "Saved best model with F1: 0.9361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 3216/3216 [09:13<00:00,  5.81it/s, loss=0.2580]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.2434, Val Loss: 0.1310, Val F1: 0.9448\n",
      "Saved best model with F1: 0.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 3216/3216 [09:14<00:00,  5.80it/s, loss=0.4455]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.2202, Val Loss: 0.1052, Val F1: 0.9651\n",
      "Saved best model with F1: 0.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 3216/3216 [09:15<00:00,  5.79it/s, loss=0.0738]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.2016, Val Loss: 0.0809, Val F1: 0.9720\n",
      "Saved best model with F1: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 3216/3216 [09:14<00:00,  5.80it/s, loss=0.1662]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.1866, Val Loss: 0.0704, Val F1: 0.9716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 3216/3216 [09:14<00:00,  5.80it/s, loss=0.4478]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.1743, Val Loss: 0.0688, Val F1: 0.9742\n",
      "Saved best model with F1: 0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 3216/3216 [09:13<00:00,  5.81it/s, loss=0.0468]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.1600, Val Loss: 0.0545, Val F1: 0.9790\n",
      "Saved best model with F1: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 3216/3216 [09:14<00:00,  5.80it/s, loss=0.0082]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.1500, Val Loss: 0.0604, Val F1: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 3216/3216 [09:17<00:00,  5.77it/s, loss=0.0778]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.1406, Val Loss: 0.0590, Val F1: 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 3216/3216 [09:17<00:00,  5.77it/s, loss=0.2913]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.1323, Val Loss: 0.0668, Val F1: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 3216/3216 [09:13<00:00,  5.81it/s, loss=0.1066]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.1195, Val Loss: 0.0552, Val F1: 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 3216/3216 [09:14<00:00,  5.80it/s, loss=0.2846]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.1134, Val Loss: 0.0392, Val F1: 0.9859\n",
      "Saved best model with F1: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 3216/3216 [09:13<00:00,  5.81it/s, loss=0.4624]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss: 0.1056, Val Loss: 0.0552, Val F1: 0.9784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 3216/3216 [09:14<00:00,  5.80it/s, loss=0.0568]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 0.0985, Val Loss: 0.0449, Val F1: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 3216/3216 [09:16<00:00,  5.78it/s, loss=0.0232]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 0.0930, Val Loss: 0.0316, Val F1: 0.9889\n",
      "Saved best model with F1: 0.9889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 3216/3216 [09:15<00:00,  5.79it/s, loss=0.0126]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 0.0891, Val Loss: 0.0295, Val F1: 0.9894\n",
      "Saved best model with F1: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 3216/3216 [09:16<00:00,  5.78it/s, loss=0.1459]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 0.0869, Val Loss: 0.0287, Val F1: 0.9899\n",
      "Saved best model with F1: 0.9899\n",
      "\n",
      "--- Evaluating CNN_Large on Test Set (cnn_3s_dataset) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0311\n",
      "Test Accuracy: 0.9886\n",
      "Test F1-score: 0.9886\n",
      "Test ROC AUC: 0.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: learning_rate ▆████▇▇▇▆▅▅▄▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_f1_score ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     test_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_loss █▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▂▄▄▅▆▇▇▇▇▇▇▇▇█▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_f1 ▁▂▄▄▅▆▇▇▇▇▇▇▇▇█▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss █▇▆▅▄▄▃▂▂▂▂▂▂▂▁▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_roc_auc ▁▃▅▆▇▇▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_accuracy 0.98863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_f1_score 0.98861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     test_loss 0.03111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_roc_auc 0.99938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_loss 0.08694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.98985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_f1 0.98986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 0.02875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_roc_auc 0.99951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  warmup_phase False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mCNN_Large_cnn_3s_dataset_114040\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/nekloyh-none/audio-deepfake-detection/runs/ccw9piht\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/nekloyh-none/audio-deepfake-detection\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250609_114040-ccw9piht/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_params_small = {\n",
    "    \"model_size\": \"CNN_Small\",\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "training_params_large = {\n",
    "    \"model_size\": \"CNN_Large\",\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "print(\"=== Training CNN_Small ===\")\n",
    "trained_model_small = run_training(training_params_small)\n",
    "\n",
    "print(\"\\n=== Training CNN_Large ===\")\n",
    "trained_model_large = run_training(training_params_large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce96a1",
   "metadata": {
    "papermill": {
     "duration": 9.870307,
     "end_time": "2025-06-09T14:50:17.189742",
     "exception": false,
     "start_time": "2025-06-09T14:50:07.319435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7611392,
     "sourceId": 12090890,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17111.516456,
   "end_time": "2025-06-09T14:50:30.082424",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T10:05:18.565968",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
